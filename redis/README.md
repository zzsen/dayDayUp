## 数据库和缓存双写一致性
### 对于读请求的处理
1. 先读cache, 再读db

2. 如果, cache hit, 则直接返回数据

3. 如果, cache miss, 则访问db, 并将数据set回缓存

### 更新策略
写操作, 既要操作数据库中的数据, 又要操作缓存里的数据。
因此, 有以下两个方案:
1. 先操作数据库, 再操作缓存

2. 先操作缓存, 再操作数据库

操作缓存可以分为更新缓存和删除缓存, 故原来的两个方案可以细化为4个方案

1. 先操作数据库, 再删除缓存

2. 先删除缓存, 再操作数据库

3. 先操作数据库, 再更新缓存

4. 先更新缓存, 再操作数据库

### 1. 先操作数据库, 再删除缓存
Cache-Aside pattern 中指出

**失效**：应用程序先从cache取数据, 没有得到, 则从数据库中取数据, 成功后, 放到缓存中。
**命中**：应用程序从cache中取数据, 取到后返回。
**更新**：先把数据存到数据库中, 成功后, 再让缓存失效。

假设有两个请求, 请求A做查询操作, 请求B做更新操作, 那么会有如下情形产生
1) 缓存刚好失效
2) 请求A查询数据库, 得一个旧值
3) 请求B将新值写入数据库
4) 请求B删除缓存
5) 请求A将查到的旧值写入缓存
ok, 如果发生上述情况, 确实是会发生脏数据。
然而, 发生这种情况的概率并不高
发生上述情况有一个先天性条件, 就是步骤3的写数据库操作比步骤2的读数据库操作耗时更短, 才有可能使得步骤4先于步骤5。可是, 数据库的读操作的速度远快于写操作的（不然做读写分离干嘛, 做读写分离的意义就是因为读操作比较快, 耗资源少）, 因此步骤3耗时比步骤2更短, 这一情形很难出现。

此外, 如果缓存删除失败, 可以引入消息队列, 应用程序自己消费消息(消息里是要删除的key), 重试删除缓存, 直至成功 

### 2. 先删除缓存, 再操作数据库
假设A、B两个线程
1) 请求A进行写操作, 删除缓存
2) 请求B查询发现缓存不存在
3) 请求B去数据库查询得到旧值
4) 请求B将旧值写入缓存
5) 请求A将新值写入数据库


为了避免这个情况, 可以使用**延时双删策略**

即:
1) 先淘汰缓存
2) 再写数据库
3) 休眠, 再次淘汰缓存

休眠时间在读数据的耗时的基础上加几百ms, 如果有主从同步延时, 则睡眠时间修改为在主从同步的延时时间基础上, 加几百ms

### 3. 先操作数据库, 再更新缓存
从线程安全考虑:
假设A、B两个线程
1) A先更新数据库
2) B再更新数据库
3) B先更新缓存
4) A后更新缓存
这样就导致数据库是最新的数据, 但是缓存中是旧的脏数据。

从实际场景上考虑
1) 如果写数据库场景比较多, 而读数据场景比较少, 采用这种方案就会导致, 数据还没读到, 缓存被频繁的更新, 浪费性能。
2) 如果写入数据库的值, 不是直接写入缓存的, 而是要经过计算再写入缓存(如, 类型转换, 序列化等)。那么, 每次写入数据库后, 都再次计算写入缓存的值, 无疑是浪费性能的。此时, 删除缓存更为适合。

### 4. 先更新缓存, 再操作数据库

假设A、B两个线程
1) A先更新缓存
2) B再更新缓存
3) B先更新数据库
4) A后更新数据库
这样就导致缓存是最新的数据, 但是数据库中是旧的脏数据。

另外, 如果更新数据库失败, 则缓存里的数据就是脏数据了


### 参考文档
双写一致性部分摘抄自 [分布式之数据库和缓存双写一致性方案解析](https://zhuanlan.zhihu.com/p/48334686)

## 缓存穿透、缓存击穿、缓存雪崩

### 缓存穿透
查询**一定不存在的数据**, 因为查不到数据所以也不会写入缓存, 所以每次都会查询数据存储, 导致数据存储压力过大。
#### 解决方案
* 由于请求的参数是不合法的(每次都请求不存在的参数), 可以使用布隆过滤器(BloomFilter)或者压缩filter提前拦截, 不合法就不让这个请求到数据库层
* 从数据库找不到时, 也缓存空对象, 即: 将key-value对写为key-null。
  >这种情况一般会将空对象设置一个较短的过期时间。

### 缓存击穿
高并发下, **当某个缓存失效时, 可能出现多个进程同时查询数据存储**, 导致数据存储压力过大。

#### 解决方案
* 设置热点数据永远不过期。

* 使用互斥锁(mutex key)
比较常用的做法, 是使用mutex。就是在缓存失效的时候（判断拿出来的值为空）, 不是立即去查数据库, 而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key, 当操作返回成功时, 再进行查数据库的操作并回设缓存; 否则, 就重试整个get缓存的方法。


### 缓存雪崩
高并发下, **大量缓存同时失效**, 导致大量请求同时查询数据存储, 导致数据存储压力过大。

#### 解决方案
* 设置热点数据永远不过期

* 使用多级缓存机制, 比如同时使用redsi和memcache缓存, 请求->redis->memcache->db

* 用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写, 从而避免失效时大量的并发请求落到底层存储系统上
  >加锁排队只是为了减轻数据库的压力, 并没有提高系统吞吐量。假设在高并发下, 缓存重建期间key是锁着的, 这是过来大部分请求都是阻塞的。会导致用户等待超时

* 将缓存失效时间分散开, 比如可以在原有的失效时间基础上增加一个随机值, 比如1-5分钟随机, 这样缓存过期时间的重复率就会降低, 就很难引发集体失效的事件。
